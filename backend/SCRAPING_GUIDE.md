# Web Scraping ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## 1ë‹¨ê³„: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

í„°ë¯¸ë„ì—ì„œ ë°±ì—”ë“œ í´ë”ë¡œ ì´ë™ í›„ ì‹¤í–‰:

```bash
cd /Users/kimdoyeon/Documents/RareSource/backend

# ê°€ìƒí™˜ê²½ í™œì„±í™” (ì´ë¯¸ í–ˆë‹¤ë©´ Skip)
source venv/bin/activate

# ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install httpx beautifulsoup4 lxml

# (ì„ íƒ) ë™ì  ì‚¬ì´íŠ¸ìš© Playwright
pip install playwright
playwright install chromium
```

## 2ë‹¨ê³„: ì˜ˆì œ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸

ì œê°€ ë§Œë“  `scraper_examples.py` íŒŒì¼ì„ ì‹¤í–‰í•´ ë³´ì„¸ìš”:

```bash
python3 scraper_examples.py
```

ì •ìƒ ì‘ë™í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤:

```
ğŸ” ì›¹ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘...
ê²€ìƒ‰ ì¤‘: TMS320C25
==================================================
âœ… ì´ 2ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:
1. Digi-Key - $12.50 (450 units)
2. Digi-Key Global - $15.00 (200 units)
```

## 3ë‹¨ê³„: ì‹¤ì œ ì‚¬ì´íŠ¸ì— ì ìš©í•˜ê¸°

### ë°©ë²• A: ê°„ë‹¨í•œ HTML ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘

`scraper_examples.py`ì˜ `scrape_octopart_example()` í•¨ìˆ˜ë¥¼ ìˆ˜ì •:

```python
# ì‹¤ì œ URLë¡œ ë³€ê²½
url = f"https://ëª©í‘œì‚¬ì´íŠ¸.com/search?q={mpn}"
response = await client.get(url, headers=headers)
soup = BeautifulSoup(response.text, 'html.parser')

# Chrome DevToolsë¡œ HTML êµ¬ì¡° ë¶„ì„ í›„
price = soup.select_one('.ê°€ê²©í´ë˜ìŠ¤ëª…').text
stock = soup.select_one('.ì¬ê³ í´ë˜ìŠ¤ëª…').text
```

### ë°©ë²• B: ê³µì‹ API ì‚¬ìš© (ê°€ì¥ ê¶Œì¥)

1. Digi-Key API í‚¤ ë°œê¸‰: https://developer.digikey.com/
2. Mouser API í‚¤ ë°œê¸‰: https://www.mouser.com/api-hub/
3. `scraper_examples.py`ì˜ API í•¨ìˆ˜ì— í‚¤ ì…ë ¥

### ë°©ë²• C: Playwrightë¡œ ë³µì¡í•œ ì‚¬ì´íŠ¸

JavaScriptë¡œ ë Œë”ë§ë˜ëŠ” ì‚¬ì´íŠ¸ëŠ” `scrape_with_playwright_example()` ì‚¬ìš©

## 4ë‹¨ê³„: main.pyì— í†µí•©

ì‹¤ì œ ìŠ¤í¬ë˜í¼ê°€ ì™„ì„±ë˜ë©´ `backend/main.py`ì˜ Mock í•¨ìˆ˜ë“¤ì„ êµì²´:

```python
# ê¸°ì¡´ Mock í•¨ìˆ˜
async def fetch_tier1_api(query: str):
    # ... Mock ë°ì´í„° ...

# ì‹¤ì œ ìŠ¤í¬ë˜í¼ë¡œ êµì²´
from scraper_examples import scrape_octopart_example

async def fetch_tier1_api(query: str):
    return await scrape_octopart_example(query)
```

## ì£¼ì˜ì‚¬í•­

### âš–ï¸ ë²•ì  ê³ ë ¤ì‚¬í•­

- **robots.txt í™•ì¸**: `https://ì‚¬ì´íŠ¸.com/robots.txt`
- **ì´ìš©ì•½ê´€ ê²€í† **: ìŠ¤í¬ë˜í•‘ì´ ê¸ˆì§€ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
- **ê³µì‹ API ìš°ì„ **: APIê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ API ì‚¬ìš©

### ğŸ›¡ï¸ ì°¨ë‹¨ ë°©ì§€ ê¸°ìˆ 

```python
# 1. Request ê°„ê²© ë‘ê¸°
await asyncio.sleep(1)  # 1ì´ˆ ëŒ€ê¸°

# 2. User-Agent ëœë¤í™”
import random
user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...',
]
headers = {'User-Agent': random.choice(user_agents)}

# 3. í”„ë¡ì‹œ ì‚¬ìš© (ê³ ê¸‰)
proxies = {
    "http://": "http://í”„ë¡ì‹œì£¼ì†Œ:í¬íŠ¸",
}
```

## ë‹¤ìŒ ë‹¨ê³„

1. ë¨¼ì € `scraper_examples.py` í…ŒìŠ¤íŠ¸ ì‹¤í–‰
2. íƒ€ê²Ÿ ì‚¬ì´íŠ¸ í•˜ë‚˜ë¥¼ ì •í•´ì„œ ì‹¤ì œ ìŠ¤í¬ë˜í¼ ì‘ì„±
3. `main.py`ì— í†µí•©
4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
